From 42756967750a327f942648013bc5254163476fe5 Mon Sep 17 00:00:00 2001
From: Robert Nelson <robertcnelson@gmail.com>
Date: Mon, 11 Sep 2017 11:01:02 -0500
Subject: [PATCH 1/2] xenomai pre-patchset

---
 arch/arm/mach-omap2/timer.c            | 121 +-----------------
 arch/arm64/mm/fault.c                  |  13 +-
 arch/powerpc/include/asm/mmu_context.h |  20 +--
 arch/powerpc/kernel/process.c          |   5 +-
 drivers/gpio/gpio-davinci.c            | 218 +++++++++++++++------------------
 5 files changed, 110 insertions(+), 267 deletions(-)

diff --git a/arch/arm/mach-omap2/timer.c b/arch/arm/mach-omap2/timer.c
index 7aed750a341a..b2f2448bfa6d 100644
--- a/arch/arm/mach-omap2/timer.c
+++ b/arch/arm/mach-omap2/timer.c
@@ -33,7 +33,6 @@
 #include <linux/clk.h>
 #include <linux/delay.h>
 #include <linux/irq.h>
-#include <linux/irqchip/arm-gic.h>
 #include <linux/clocksource.h>
 #include <linux/clockchips.h>
 #include <linux/slab.h>
@@ -64,20 +63,11 @@
 #define INCREMENTER_DENUMERATOR_RELOAD_OFFSET		0x14
 #define NUMERATOR_DENUMERATOR_MASK			0xfffff000
 
-#define AM43XX_GIC_CPU_BASE				0x48240100
-
-static void __iomem *gic_cpu_base;
-
 /* Clockevent code */
 
 static struct omap_dm_timer clkev;
 static struct clock_event_device clockevent_gpt;
 
-/* Clockevent hwmod for am335x and am437x suspend */
-struct omap_hwmod *clockevent_gpt_hwmod;
-static struct irq_chip *clkev_irq_chip;
-static struct irq_desc *clkev_irq_desc;
-
 #ifdef CONFIG_SOC_HAS_REALTIME_COUNTER
 static unsigned long arch_timer_freq;
 
@@ -135,62 +125,6 @@ static int omap2_gp_timer_set_periodic(struct clock_event_device *evt)
 	return 0;
 }
 
-static int omap_clkevt_late_ack_init(void)
-{
-	gic_cpu_base = ioremap(AM43XX_GIC_CPU_BASE, SZ_4K);
-
-	if (!gic_cpu_base)
-		return -ENOMEM;
-
-	return 0;
-}
-
-static void omap_clkevt_late_ack(void)
-{
-	u32 val;
-
-	if (!clkev_irq_chip)
-		return;
-
-	/*
-	 * For the gic to properly clear an interrupt it must be read
-	 * from INTACK register
-	 */
-	if (gic_cpu_base)
-		val = readl_relaxed(gic_cpu_base + GIC_CPU_INTACK);
-	if (clkev_irq_chip->irq_ack)
-		clkev_irq_chip->irq_ack(&clkev_irq_desc->irq_data);
-	if (clkev_irq_chip->irq_eoi)
-		clkev_irq_chip->irq_eoi(&clkev_irq_desc->irq_data);
-
-	clkev_irq_chip->irq_unmask(&clkev_irq_desc->irq_data);
-}
-
-static void omap_clkevt_idle(struct clock_event_device *unused)
-{
-	if (!clockevent_gpt_hwmod)
-		return;
-
-	/*
-	 * It is possible for a late interrupt to be generated which will
-	 * cause a suspend failure. Let's ack it here both in the timer
-	 * and the interrupt controller to avoid this.
-	 */
-	__omap_dm_timer_write_status(&clkev, OMAP_TIMER_INT_OVERFLOW);
-	omap_clkevt_late_ack();
-
-	omap_hwmod_idle(clockevent_gpt_hwmod);
-}
-
-static void omap_clkevt_unidle(struct clock_event_device *unused)
-{
-	if (!clockevent_gpt_hwmod)
-		return;
-
-	omap_hwmod_enable(clockevent_gpt_hwmod);
-	__omap_dm_timer_int_enable(&clkev, OMAP_TIMER_INT_OVERFLOW);
-}
-
 static struct clock_event_device clockevent_gpt = {
 	.features		= CLOCK_EVT_FEAT_PERIODIC |
 				  CLOCK_EVT_FEAT_ONESHOT,
@@ -424,22 +358,6 @@ static void __init omap2_gp_clockevent_init(int gptimer_id,
 					3, /* Timer internal resynch latency */
 					0xffffffff);
 
-	if (soc_is_am33xx() || soc_is_am43xx()) {
-		clockevent_gpt.suspend = omap_clkevt_idle;
-		clockevent_gpt.resume = omap_clkevt_unidle;
-
-		clockevent_gpt_hwmod =
-			omap_hwmod_lookup(clockevent_gpt.name);
-
-		clkev_irq_desc = irq_to_desc(clkev.irq);
-		if (clkev_irq_desc)
-			clkev_irq_chip = irq_desc_get_chip(clkev_irq_desc);
-
-	}
-
-	if (soc_is_am437x())
-		omap_clkevt_late_ack_init();
-
 	pr_info("OMAP clockevent source: %s at %lu Hz\n", clockevent_gpt.name,
 		clkev.rate);
 }
@@ -458,7 +376,7 @@ static cycle_t clocksource_read_cycles(struct clocksource *cs)
 }
 
 static struct clocksource clocksource_gpt = {
-	.rating		= 290,
+	.rating		= 300,
 	.read		= clocksource_read_cycles,
 	.mask		= CLOCKSOURCE_MASK(32),
 	.flags		= CLOCK_SOURCE_IS_CONTINUOUS,
@@ -531,38 +449,6 @@ static int __init __maybe_unused omap2_sync32k_clocksource_init(void)
 	return ret;
 }
 
-static unsigned int omap2_gptimer_clksrc_load;
-
-static void omap2_gptimer_clksrc_suspend(struct clocksource *unused)
-{
-	struct omap_hwmod *oh;
-
-	omap2_gptimer_clksrc_load =
-		__omap_dm_timer_read_counter(&clksrc, OMAP_TIMER_NONPOSTED);
-
-	oh = omap_hwmod_lookup(clocksource_gpt.name);
-	if (!oh)
-		return;
-
-	omap_hwmod_idle(oh);
-}
-
-static void omap2_gptimer_clksrc_resume(struct clocksource *unused)
-{
-	struct omap_hwmod *oh;
-
-	oh = omap_hwmod_lookup(clocksource_gpt.name);
-	if (!oh)
-		return;
-
-	omap_hwmod_enable(oh);
-
-	__omap_dm_timer_load_start(&clksrc,
-				   OMAP_TIMER_CTRL_ST | OMAP_TIMER_CTRL_AR,
-				   omap2_gptimer_clksrc_load,
-				   OMAP_TIMER_NONPOSTED);
-}
-
 static void __init omap2_gptimer_clocksource_init(int gptimer_id,
 						  const char *fck_source,
 						  const char *property)
@@ -572,11 +458,6 @@ static void __init omap2_gptimer_clocksource_init(int gptimer_id,
 	clksrc.id = gptimer_id;
 	clksrc.errata = omap_dm_timer_get_errata();
 
-	if (soc_is_am43xx()) {
-		clocksource_gpt.suspend = omap2_gptimer_clksrc_suspend;
-		clocksource_gpt.resume = omap2_gptimer_clksrc_resume;
-	}
-
 	res = omap_dm_timer_init_one(&clksrc, fck_source, property,
 				     &clocksource_gpt.name,
 				     OMAP_TIMER_NONPOSTED);
diff --git a/arch/arm64/mm/fault.c b/arch/arm64/mm/fault.c
index fec5b1ce97f8..8b8ac3db4092 100644
--- a/arch/arm64/mm/fault.c
+++ b/arch/arm64/mm/fault.c
@@ -101,21 +101,21 @@ void show_pte(struct mm_struct *mm, unsigned long addr)
 			break;
 
 		pud = pud_offset(pgd, addr);
-		pr_cont(", *pud=%016llx", pud_val(*pud));
+		printk(", *pud=%016llx", pud_val(*pud));
 		if (pud_none(*pud) || pud_bad(*pud))
 			break;
 
 		pmd = pmd_offset(pud, addr);
-		pr_cont(", *pmd=%016llx", pmd_val(*pmd));
+		printk(", *pmd=%016llx", pmd_val(*pmd));
 		if (pmd_none(*pmd) || pmd_bad(*pmd))
 			break;
 
 		pte = pte_offset_map(pmd, addr);
-		pr_cont(", *pte=%016llx", pte_val(*pte));
+		printk(", *pte=%016llx", pte_val(*pte));
 		pte_unmap(pte);
 	} while(0);
 
-	pr_cont("\n");
+	printk("\n");
 }
 
 #ifdef CONFIG_ARM64_HW_AFDBM
@@ -373,11 +373,8 @@ static int __kprobes do_page_fault(unsigned long addr, unsigned int esr,
 	 * signal first. We do not need to release the mmap_sem because it
 	 * would already be released in __lock_page_or_retry in mm/filemap.c.
 	 */
-	if ((fault & VM_FAULT_RETRY) && fatal_signal_pending(current)) {
-		if (!user_mode(regs))
-			goto no_context;
+	if ((fault & VM_FAULT_RETRY) && fatal_signal_pending(current))
 		return 0;
-	}
 
 	/*
 	 * Major/minor page fault accounting is only done on the initial
diff --git a/arch/powerpc/include/asm/mmu_context.h b/arch/powerpc/include/asm/mmu_context.h
index fe208b70b8b1..0012f0353fd6 100644
--- a/arch/powerpc/include/asm/mmu_context.h
+++ b/arch/powerpc/include/asm/mmu_context.h
@@ -75,27 +75,9 @@ static inline void switch_mm_irqs_off(struct mm_struct *prev,
 				      struct task_struct *tsk)
 {
 	/* Mark this context has been used on the new CPU */
-	if (!cpumask_test_cpu(smp_processor_id(), mm_cpumask(next))) {
+	if (!cpumask_test_cpu(smp_processor_id(), mm_cpumask(next)))
 		cpumask_set_cpu(smp_processor_id(), mm_cpumask(next));
 
-		/*
-		 * This full barrier orders the store to the cpumask above vs
-		 * a subsequent operation which allows this CPU to begin loading
-		 * translations for next.
-		 *
-		 * When using the radix MMU that operation is the load of the
-		 * MMU context id, which is then moved to SPRN_PID.
-		 *
-		 * For the hash MMU it is either the first load from slb_cache
-		 * in switch_slb(), and/or the store of paca->mm_ctx_id in
-		 * copy_mm_to_paca().
-		 *
-		 * On the read side the barrier is in pte_xchg(), which orders
-		 * the store to the PTE vs the load of mm_cpumask.
-		 */
-		smp_mb();
-	}
-
 	/* 32-bit keeps track of the current PGDIR in the thread struct */
 #ifdef CONFIG_PPC32
 	tsk->thread.pgdir = next->pgd;
diff --git a/arch/powerpc/kernel/process.c b/arch/powerpc/kernel/process.c
index 1c141d50fbc6..b249c2fb99c8 100644
--- a/arch/powerpc/kernel/process.c
+++ b/arch/powerpc/kernel/process.c
@@ -359,8 +359,7 @@ void enable_kernel_vsx(void)
 
 	cpumsr = msr_check_and_set(MSR_FP|MSR_VEC|MSR_VSX);
 
-	if (current->thread.regs &&
-	    (current->thread.regs->msr & (MSR_VSX|MSR_VEC|MSR_FP))) {
+	if (current->thread.regs && (current->thread.regs->msr & MSR_VSX)) {
 		check_if_tm_restore_required(current);
 		/*
 		 * If a thread has already been reclaimed then the
@@ -384,7 +383,7 @@ void flush_vsx_to_thread(struct task_struct *tsk)
 {
 	if (tsk->thread.regs) {
 		preempt_disable();
-		if (tsk->thread.regs->msr & (MSR_VSX|MSR_VEC|MSR_FP)) {
+		if (tsk->thread.regs->msr & MSR_VSX) {
 			BUG_ON(tsk != current);
 			giveup_vsx(tsk);
 		}
diff --git a/drivers/gpio/gpio-davinci.c b/drivers/gpio/gpio-davinci.c
index e9440de6e7a9..dd262f00295d 100644
--- a/drivers/gpio/gpio-davinci.c
+++ b/drivers/gpio/gpio-davinci.c
@@ -42,7 +42,25 @@ typedef struct irq_chip *(*gpio_get_irq_chip_cb_t)(unsigned int irq);
 #define BINTEN	0x8 /* GPIO Interrupt Per-Bank Enable Register */
 
 static void __iomem *gpio_base;
-static unsigned int offset_array[5] = {0x10, 0x38, 0x60, 0x88, 0xb0};
+
+static struct davinci_gpio_regs __iomem *gpio2regs(unsigned gpio)
+{
+	void __iomem *ptr;
+
+	if (gpio < 32 * 1)
+		ptr = gpio_base + 0x10;
+	else if (gpio < 32 * 2)
+		ptr = gpio_base + 0x38;
+	else if (gpio < 32 * 3)
+		ptr = gpio_base + 0x60;
+	else if (gpio < 32 * 4)
+		ptr = gpio_base + 0x88;
+	else if (gpio < 32 * 5)
+		ptr = gpio_base + 0xb0;
+	else
+		ptr = NULL;
+	return ptr;
+}
 
 static inline struct davinci_gpio_regs __iomem *irq2regs(struct irq_data *d)
 {
@@ -62,13 +80,10 @@ static inline int __davinci_direction(struct gpio_chip *chip,
 			unsigned offset, bool out, int value)
 {
 	struct davinci_gpio_controller *d = gpiochip_get_data(chip);
-	struct davinci_gpio_regs __iomem *g;
+	struct davinci_gpio_regs __iomem *g = d->regs;
 	unsigned long flags;
 	u32 temp;
-	int bank = offset / 32;
-	u32 mask = __gpio_mask(offset);
-
-	g = d->regs[bank];
+	u32 mask = 1 << offset;
 
 	spin_lock_irqsave(&d->lock, flags);
 	temp = readl_relaxed(&g->dir);
@@ -105,12 +120,9 @@ davinci_direction_out(struct gpio_chip *chip, unsigned offset, int value)
 static int davinci_gpio_get(struct gpio_chip *chip, unsigned offset)
 {
 	struct davinci_gpio_controller *d = gpiochip_get_data(chip);
-	struct davinci_gpio_regs __iomem *g;
-	int bank = offset / 32;
-
-	g = d->regs[bank];
+	struct davinci_gpio_regs __iomem *g = d->regs;
 
-	return !!(__gpio_mask(offset) & readl_relaxed(&g->in_data));
+	return !!((1 << offset) & readl_relaxed(&g->in_data));
 }
 
 /*
@@ -120,13 +132,9 @@ static void
 davinci_gpio_set(struct gpio_chip *chip, unsigned offset, int value)
 {
 	struct davinci_gpio_controller *d = gpiochip_get_data(chip);
-	struct davinci_gpio_regs __iomem *g;
-	int bank = offset / 32;
+	struct davinci_gpio_regs __iomem *g = d->regs;
 
-	g = d->regs[bank];
-
-	writel_relaxed(__gpio_mask(offset),
-		       value ? &g->set_data : &g->clr_data);
+	writel_relaxed((1 << offset), value ? &g->set_data : &g->clr_data);
 }
 
 static struct davinci_gpio_platform_data *
@@ -163,15 +171,36 @@ davinci_gpio_get_pdata(struct platform_device *pdev)
 	return NULL;
 }
 
+#ifdef CONFIG_OF_GPIO
+static int davinci_gpio_of_xlate(struct gpio_chip *gc,
+			     const struct of_phandle_args *gpiospec,
+			     u32 *flags)
+{
+	struct davinci_gpio_controller *chips = dev_get_drvdata(gc->parent);
+	struct davinci_gpio_platform_data *pdata = dev_get_platdata(gc->parent);
+
+	if (gpiospec->args[0] > pdata->ngpio)
+		return -EINVAL;
+
+	if (gc != &chips[gpiospec->args[0] / 32].chip)
+		return -EINVAL;
+
+	if (flags)
+		*flags = gpiospec->args[1];
+
+	return gpiospec->args[0] % 32;
+}
+#endif
+
 static int davinci_gpio_probe(struct platform_device *pdev)
 {
-	int gpio, bank;
+	int i, base;
 	unsigned ngpio, nbank;
 	struct davinci_gpio_controller *chips;
 	struct davinci_gpio_platform_data *pdata;
+	struct davinci_gpio_regs __iomem *regs;
 	struct device *dev = &pdev->dev;
 	struct resource *res;
-	static int bank_base;
 
 	pdata = davinci_gpio_get_pdata(pdev);
 	if (!pdata) {
@@ -207,26 +236,38 @@ static int davinci_gpio_probe(struct platform_device *pdev)
 	if (IS_ERR(gpio_base))
 		return PTR_ERR(gpio_base);
 
-	chips->chip.label = "Davinci";
-	chips->chip.direction_input = davinci_direction_in;
-	chips->chip.get = davinci_gpio_get;
-	chips->chip.direction_output = davinci_direction_out;
-	chips->chip.set = davinci_gpio_set;
-	chips->chip.ngpio = ngpio;
-	chips->chip.base = bank_base;
+	for (i = 0, base = 0; base < ngpio; i++, base += 32) {
+		chips[i].chip.label = "DaVinci";
+
+		chips[i].chip.direction_input = davinci_direction_in;
+		chips[i].chip.get = davinci_gpio_get;
+		chips[i].chip.direction_output = davinci_direction_out;
+		chips[i].chip.set = davinci_gpio_set;
+
+		chips[i].chip.base = base;
+		chips[i].chip.ngpio = ngpio - base;
+		if (chips[i].chip.ngpio > 32)
+			chips[i].chip.ngpio = 32;
 
 #ifdef CONFIG_OF_GPIO
-	chips->chip.of_gpio_n_cells = 2;
-	chips->chip.parent = dev;
-	chips->chip.of_node = dev->of_node;
+		chips[i].chip.of_gpio_n_cells = 2;
+		chips[i].chip.of_xlate = davinci_gpio_of_xlate;
+		chips[i].chip.parent = dev;
+		chips[i].chip.of_node = dev->of_node;
 #endif
-	spin_lock_init(&chips->lock);
-	bank_base += ngpio;
+		spin_lock_init(&chips[i].lock);
+
+		regs = gpio2regs(base);
+		if (!regs)
+			return -ENXIO;
+		chips[i].regs = regs;
+		chips[i].set_data = &regs->set_data;
+		chips[i].clr_data = &regs->clr_data;
+		chips[i].in_data = &regs->in_data;
 
-	for (gpio = 0, bank = 0; gpio < ngpio; gpio += 32, bank++)
-		chips->regs[bank] = gpio_base + offset_array[bank];
+		gpiochip_add_data(&chips[i].chip, &chips[i]);
+	}
 
-	gpiochip_add_data(&chips->chip, chips);
 	platform_set_drvdata(pdev, chips);
 	davinci_gpio_irq_setup(pdev);
 	return 0;
@@ -287,19 +328,16 @@ static struct irq_chip gpio_irqchip = {
 
 static void gpio_irq_handler(struct irq_desc *desc)
 {
+	unsigned int irq = irq_desc_get_irq(desc);
 	struct davinci_gpio_regs __iomem *g;
 	u32 mask = 0xffff;
-	int bank_num;
 	struct davinci_gpio_controller *d;
-	struct davinci_gpio_irq_data *irqdata;
 
-	irqdata = (struct davinci_gpio_irq_data *)irq_desc_get_handler_data(desc);
-	bank_num = irqdata->bank_num;
-	g = irqdata->regs;
-	d = irqdata->chip;
+	d = (struct davinci_gpio_controller *)irq_desc_get_handler_data(desc);
+	g = (struct davinci_gpio_regs __iomem *)d->regs;
 
 	/* we only care about one bank */
-	if ((bank_num % 2) == 1)
+	if (irq & 1)
 		mask <<= 16;
 
 	/* temporarily mask (level sensitive) parent IRQ */
@@ -307,7 +345,6 @@ static void gpio_irq_handler(struct irq_desc *desc)
 	while (1) {
 		u32		status;
 		int		bit;
-		irq_hw_number_t hw_irq;
 
 		/* ack any irqs */
 		status = readl_relaxed(&g->intstat) & mask;
@@ -320,13 +357,9 @@ static void gpio_irq_handler(struct irq_desc *desc)
 		while (status) {
 			bit = __ffs(status);
 			status &= ~BIT(bit);
-			/* Max number of gpios per controller is 144 so
-			 * hw_irq will be in [0..143]
-			 */
-			hw_irq = (bank_num / 2) * 32 + bit;
-
 			generic_handle_irq(
-				irq_find_mapping(d->irq_domain, hw_irq));
+				irq_find_mapping(d->irq_domain,
+						 d->chip.base + bit));
 		}
 	}
 	chained_irq_exit(irq_desc_get_chip(desc), desc);
@@ -338,7 +371,7 @@ static int gpio_to_irq_banked(struct gpio_chip *chip, unsigned offset)
 	struct davinci_gpio_controller *d = gpiochip_get_data(chip);
 
 	if (d->irq_domain)
-		return irq_create_mapping(d->irq_domain, offset);
+		return irq_create_mapping(d->irq_domain, d->chip.base + offset);
 	else
 		return -ENXIO;
 }
@@ -352,7 +385,7 @@ static int gpio_to_irq_unbanked(struct gpio_chip *chip, unsigned offset)
 	 * can provide direct-mapped IRQs to AINTC (up to 32 GPIOs).
 	 */
 	if (offset < d->gpio_unbanked)
-		return d->base_irq + offset;
+		return d->gpio_irq + offset;
 	else
 		return -ENODEV;
 }
@@ -364,8 +397,8 @@ static int gpio_irq_type_unbanked(struct irq_data *data, unsigned trigger)
 	u32 mask;
 
 	d = (struct davinci_gpio_controller *)irq_data_get_irq_handler_data(data);
-	g = (struct davinci_gpio_regs __iomem *)d->regs[0];
-	mask = __gpio_mask(data->irq - d->base_irq);
+	g = (struct davinci_gpio_regs __iomem *)d->regs;
+	mask = __gpio_mask(data->irq - d->gpio_irq);
 
 	if (trigger & ~(IRQ_TYPE_EDGE_FALLING | IRQ_TYPE_EDGE_RISING))
 		return -EINVAL;
@@ -382,9 +415,7 @@ static int
 davinci_gpio_irq_map(struct irq_domain *d, unsigned int irq,
 		     irq_hw_number_t hw)
 {
-	struct davinci_gpio_controller *chips =
-				(struct davinci_gpio_controller *)d->host_data;
-	struct davinci_gpio_regs __iomem *g = chips->regs[hw / 32];
+	struct davinci_gpio_regs __iomem *g = gpio2regs(hw);
 
 	irq_set_chip_and_handler_name(irq, &gpio_irqchip, handle_simple_irq,
 				"davinci_gpio");
@@ -419,26 +450,6 @@ static struct irq_chip *keystone_gpio_get_irq_chip(unsigned int irq)
 
 static const struct of_device_id davinci_gpio_ids[];
 
-struct gpio_driver_data {
-	gpio_get_irq_chip_cb_t gpio_get_irq_chip;
-	bool clk_optional;
-};
-
-static struct gpio_driver_data davinci_data = {
-	.gpio_get_irq_chip = davinci_gpio_get_irq_chip,
-	.clk_optional = false,
-};
-
-static struct gpio_driver_data keystone_data = {
-	.gpio_get_irq_chip = keystone_gpio_get_irq_chip,
-	.clk_optional = false,
-};
-
-static struct gpio_driver_data k2g_data = {
-	.gpio_get_irq_chip = keystone_gpio_get_irq_chip,
-	.clk_optional = true,
-};
-
 /*
  * NOTE:  for suspend/resume, probably best to make a platform_device with
  * suspend_late/resume_resume calls hooking into results of the set_wake()
@@ -462,8 +473,6 @@ static int davinci_gpio_irq_setup(struct platform_device *pdev)
 	struct irq_domain	*irq_domain = NULL;
 	const struct of_device_id *match;
 	struct irq_chip *irq_chip;
-	struct davinci_gpio_irq_data *irqdata;
-	struct gpio_driver_data *driver_data = NULL;
 	gpio_get_irq_chip_cb_t gpio_get_irq_chip;
 
 	/*
@@ -472,10 +481,8 @@ static int davinci_gpio_irq_setup(struct platform_device *pdev)
 	gpio_get_irq_chip = davinci_gpio_get_irq_chip;
 	match = of_match_device(of_match_ptr(davinci_gpio_ids),
 				dev);
-	if (match) {
-		driver_data = (struct gpio_driver_data *)match->data;
-		gpio_get_irq_chip = driver_data->gpio_get_irq_chip;
-	}
+	if (match)
+		gpio_get_irq_chip = (gpio_get_irq_chip_cb_t)match->data;
 
 	ngpio = pdata->ngpio;
 	res = platform_get_resource(pdev, IORESOURCE_IRQ, 0);
@@ -491,9 +498,6 @@ static int davinci_gpio_irq_setup(struct platform_device *pdev)
 		return -ENODEV;
 	}
 
-	if (driver_data && driver_data->clk_optional)
-		goto skip_clk_handling;
-
 	clk = devm_clk_get(dev, "gpio");
 	if (IS_ERR(clk)) {
 		printk(KERN_ERR "Error %ld getting gpio clock?\n",
@@ -502,7 +506,6 @@ static int davinci_gpio_irq_setup(struct platform_device *pdev)
 	}
 	clk_prepare_enable(clk);
 
-skip_clk_handling:
 	if (!pdata->gpio_unbanked) {
 		irq = irq_alloc_descs(-1, 0, ngpio, 0);
 		if (irq < 0) {
@@ -525,8 +528,10 @@ static int davinci_gpio_irq_setup(struct platform_device *pdev)
 	 * IRQs, while the others use banked IRQs, would need some setup
 	 * tweaks to recognize hardware which can do that.
 	 */
-	chips->chip.to_irq = gpio_to_irq_banked;
-	chips->irq_domain = irq_domain;
+	for (gpio = 0, bank = 0; gpio < ngpio; bank++, gpio += 32) {
+		chips[bank].chip.to_irq = gpio_to_irq_banked;
+		chips[bank].irq_domain = irq_domain;
+	}
 
 	/*
 	 * AINTC can handle direct/unbanked IRQs for GPIOs, with the GPIO
@@ -535,9 +540,9 @@ static int davinci_gpio_irq_setup(struct platform_device *pdev)
 	 */
 	if (pdata->gpio_unbanked) {
 		/* pass "bank 0" GPIO IRQs to AINTC */
-		chips->chip.to_irq = gpio_to_irq_unbanked;
-		chips->base_irq = bank_irq;
-		chips->gpio_unbanked = pdata->gpio_unbanked;
+		chips[0].chip.to_irq = gpio_to_irq_unbanked;
+		chips[0].gpio_irq = bank_irq;
+		chips[0].gpio_unbanked = pdata->gpio_unbanked;
 		binten = GENMASK(pdata->gpio_unbanked / 16, 0);
 
 		/* AINTC handles mask/unmask; GPIO handles triggering */
@@ -547,14 +552,14 @@ static int davinci_gpio_irq_setup(struct platform_device *pdev)
 		irq_chip->irq_set_type = gpio_irq_type_unbanked;
 
 		/* default trigger: both edges */
-		g = chips->regs[0];
+		g = gpio2regs(0);
 		writel_relaxed(~0, &g->set_falling);
 		writel_relaxed(~0, &g->set_rising);
 
 		/* set the direct IRQs up to use that irqchip */
 		for (gpio = 0; gpio < pdata->gpio_unbanked; gpio++, irq++) {
 			irq_set_chip(irq, irq_chip);
-			irq_set_handler_data(irq, chips);
+			irq_set_handler_data(irq, &chips[gpio / 32]);
 			irq_set_status_flags(irq, IRQ_TYPE_EDGE_BOTH);
 		}
 
@@ -567,7 +572,7 @@ static int davinci_gpio_irq_setup(struct platform_device *pdev)
 	 */
 	for (gpio = 0, bank = 0; gpio < ngpio; bank++, bank_irq++, gpio += 16) {
 		/* disabled by default, enabled only as needed */
-		g = chips->regs[bank / 2];
+		g = gpio2regs(gpio);
 		writel_relaxed(~0, &g->clr_falling);
 		writel_relaxed(~0, &g->clr_rising);
 
@@ -576,19 +581,8 @@ static int davinci_gpio_irq_setup(struct platform_device *pdev)
 		 * gpio irqs. Pass the irq bank's corresponding controller to
 		 * the chained irq handler.
 		 */
-		irqdata = devm_kzalloc(&pdev->dev,
-				       sizeof(struct
-					      davinci_gpio_irq_data),
-					      GFP_KERNEL);
-		if (!irqdata)
-			return -ENOMEM;
-
-		irqdata->regs = g;
-		irqdata->bank_num = bank;
-		irqdata->chip = chips;
-
 		irq_set_chained_handler_and_data(bank_irq, gpio_irq_handler,
-						 irqdata);
+						 &chips[gpio / 32]);
 
 		binten |= BIT(bank);
 	}
@@ -605,18 +599,8 @@ static int davinci_gpio_irq_setup(struct platform_device *pdev)
 
 #if IS_ENABLED(CONFIG_OF)
 static const struct of_device_id davinci_gpio_ids[] = {
-	{
-		.compatible = "ti,keystone-gpio",
-		.data = &keystone_data,
-	},
-	{
-		.compatible = "ti,dm6441-gpio",
-		.data = &davinci_data,
-	},
-	{
-		.compatible = "ti,k2g-gpio",
-		.data = &k2g_data,
-	},
+	{ .compatible = "ti,keystone-gpio", keystone_gpio_get_irq_chip},
+	{ .compatible = "ti,dm6441-gpio", davinci_gpio_get_irq_chip},
 	{ /* sentinel */ },
 };
 MODULE_DEVICE_TABLE(of, davinci_gpio_ids);
-- 
2.14.1

