From c31d783481a718375500dc4f30cc4b532b14ffd8 Mon Sep 17 00:00:00 2001
From: Robert Nelson <robertcnelson@gmail.com>
Date: Thu, 16 Mar 2017 12:47:27 -0500
Subject: [PATCH 1/2] xenomai pre-patchset

---
 arch/arm/mach-omap2/timer.c    |  80 +----
 arch/x86/kernel/apic/io_apic.c |   2 -
 drivers/gpio/gpio-davinci.c    | 122 +++-----
 drivers/memory/omap-gpmc.c     | 662 +++++++++++++++--------------------------
 4 files changed, 282 insertions(+), 584 deletions(-)

diff --git a/arch/arm/mach-omap2/timer.c b/arch/arm/mach-omap2/timer.c
index 25f0eee33869..f86692dbcfd5 100644
--- a/arch/arm/mach-omap2/timer.c
+++ b/arch/arm/mach-omap2/timer.c
@@ -68,9 +68,6 @@
 static struct omap_dm_timer clkev;
 static struct clock_event_device clockevent_gpt;
 
-/* Clockevent hwmod for am335x and am437x suspend */
-struct omap_hwmod *clockevent_gpt_hwmod;
-
 #ifdef CONFIG_SOC_HAS_REALTIME_COUNTER
 static unsigned long arch_timer_freq;
 
@@ -128,23 +125,6 @@ static int omap2_gp_timer_set_periodic(struct clock_event_device *evt)
 	return 0;
 }
 
-static void omap_clkevt_idle(struct clock_event_device *unused)
-{
-	if (!clockevent_gpt_hwmod)
-		return;
-
-	omap_hwmod_idle(clockevent_gpt_hwmod);
-}
-
-static void omap_clkevt_unidle(struct clock_event_device *unused)
-{
-	if (!clockevent_gpt_hwmod)
-		return;
-
-	omap_hwmod_enable(clockevent_gpt_hwmod);
-	__omap_dm_timer_int_enable(&clkev, OMAP_TIMER_INT_OVERFLOW);
-}
-
 static struct clock_event_device clockevent_gpt = {
 	.features		= CLOCK_EVT_FEAT_PERIODIC |
 				  CLOCK_EVT_FEAT_ONESHOT,
@@ -214,8 +194,8 @@ static struct device_node * __init omap_get_timer_dt(const struct of_device_id *
 /**
  * omap_dmtimer_init - initialisation function when device tree is used
  *
- * For secure OMAP3/DRA7xx devices, timers with device type "timer-secure"
- * cannot be used by the kernel as they are reserved. Therefore, to prevent the
+ * For secure OMAP3 devices, timers with device type "timer-secure" cannot
+ * be used by the kernel as they are reserved. Therefore, to prevent the
  * kernel registering these devices remove them dynamically from the device
  * tree on boot.
  */
@@ -223,7 +203,7 @@ static void __init omap_dmtimer_init(void)
 {
 	struct device_node *np;
 
-	if (!cpu_is_omap34xx() && !soc_is_dra7xx())
+	if (!cpu_is_omap34xx())
 		return;
 
 	/* If we are a secure device, remove any secure timer nodes */
@@ -377,14 +357,6 @@ static void __init omap2_gp_clockevent_init(int gptimer_id,
 					3, /* Timer internal resynch latency */
 					0xffffffff);
 
-	if (soc_is_am33xx() || soc_is_am43xx()) {
-		clockevent_gpt.suspend = omap_clkevt_idle;
-		clockevent_gpt.resume = omap_clkevt_unidle;
-
-		clockevent_gpt_hwmod =
-			omap_hwmod_lookup(clockevent_gpt.name);
-	}
-
 	pr_info("OMAP clockevent source: %s at %lu Hz\n", clockevent_gpt.name,
 		clkev.rate);
 }
@@ -403,7 +375,7 @@ static cycle_t clocksource_read_cycles(struct clocksource *cs)
 }
 
 static struct clocksource clocksource_gpt = {
-	.rating		= 290,
+	.rating		= 300,
 	.read		= clocksource_read_cycles,
 	.mask		= CLOCKSOURCE_MASK(32),
 	.flags		= CLOCK_SOURCE_IS_CONTINUOUS,
@@ -476,38 +448,6 @@ static int __init __maybe_unused omap2_sync32k_clocksource_init(void)
 	return ret;
 }
 
-static unsigned omap2_gptimer_clksrc_load;
-
-static void omap2_gptimer_clksrc_suspend(struct clocksource *unused)
-{
-	struct omap_hwmod *oh;
-
-	omap2_gptimer_clksrc_load =
-		__omap_dm_timer_read_counter(&clksrc, OMAP_TIMER_NONPOSTED);
-
-	oh = omap_hwmod_lookup(clocksource_gpt.name);
-	if (!oh)
-		return;
-
-	omap_hwmod_idle(oh);
-}
-
-static void omap2_gptimer_clksrc_resume(struct clocksource *unused)
-{
-	struct omap_hwmod *oh;
-
-	oh = omap_hwmod_lookup(clocksource_gpt.name);
-	if (!oh)
-		return;
-
-	omap_hwmod_enable(oh);
-
-	__omap_dm_timer_load_start(&clksrc,
-				   OMAP_TIMER_CTRL_ST | OMAP_TIMER_CTRL_AR,
-				   omap2_gptimer_clksrc_load,
-				   OMAP_TIMER_NONPOSTED);
-}
-
 static void __init omap2_gptimer_clocksource_init(int gptimer_id,
 						  const char *fck_source,
 						  const char *property)
@@ -517,11 +457,6 @@ static void __init omap2_gptimer_clocksource_init(int gptimer_id,
 	clksrc.id = gptimer_id;
 	clksrc.errata = omap_dm_timer_get_errata();
 
-	if (soc_is_am43xx()) {
-		clocksource_gpt.suspend = omap2_gptimer_clksrc_suspend;
-		clocksource_gpt.resume = omap2_gptimer_clksrc_resume;
-	}
-
 	res = omap_dm_timer_init_one(&clksrc, fck_source, property,
 				     &clocksource_gpt.name,
 				     OMAP_TIMER_NONPOSTED);
@@ -573,19 +508,16 @@ void __init omap3_secure_sync32k_timer_init(void)
 }
 #endif /* CONFIG_ARCH_OMAP3 */
 
-#if defined(CONFIG_ARCH_OMAP3) || defined(CONFIG_SOC_AM33XX) || \
-	defined(CONFIG_SOC_AM43XX)
+#if defined(CONFIG_ARCH_OMAP3) || defined(CONFIG_SOC_AM33XX)
 void __init omap3_gptimer_timer_init(void)
 {
 	__omap_sync32k_timer_init(2, "timer_sys_ck", NULL,
 			1, "timer_sys_ck", "ti,timer-alwon", true);
-	if (of_have_populated_dt())
-		clocksource_probe();
 }
 #endif
 
 #if defined(CONFIG_ARCH_OMAP4) || defined(CONFIG_SOC_OMAP5) ||		\
-	defined(CONFIG_SOC_DRA7XX)
+	defined(CONFIG_SOC_DRA7XX) || defined(CONFIG_SOC_AM43XX)
 static void __init omap4_sync32k_timer_init(void)
 {
 	__omap_sync32k_timer_init(1, "timer_32k_ck", "ti,timer-alwon",
diff --git a/arch/x86/kernel/apic/io_apic.c b/arch/x86/kernel/apic/io_apic.c
index 8ca533b8c606..fdb0fbfb1197 100644
--- a/arch/x86/kernel/apic/io_apic.c
+++ b/arch/x86/kernel/apic/io_apic.c
@@ -2115,7 +2115,6 @@ static inline void __init check_timer(void)
 			if (idx != -1 && irq_trigger(idx))
 				unmask_ioapic_irq(irq_get_chip_data(0));
 		}
-		irq_domain_deactivate_irq(irq_data);
 		irq_domain_activate_irq(irq_data);
 		if (timer_irq_works()) {
 			if (disable_timer_pin_1 > 0)
@@ -2137,7 +2136,6 @@ static inline void __init check_timer(void)
 		 * legacy devices should be connected to IO APIC #0
 		 */
 		replace_pin_at_irq_node(data, node, apic1, pin1, apic2, pin2);
-		irq_domain_deactivate_irq(irq_data);
 		irq_domain_activate_irq(irq_data);
 		legacy_pic->unmask(0);
 		if (timer_irq_works()) {
diff --git a/drivers/gpio/gpio-davinci.c b/drivers/gpio/gpio-davinci.c
index 90c6b09793dc..5e715388803d 100644
--- a/drivers/gpio/gpio-davinci.c
+++ b/drivers/gpio/gpio-davinci.c
@@ -45,7 +45,25 @@ typedef struct irq_chip *(*gpio_get_irq_chip_cb_t)(unsigned int irq);
 	container_of(chip, struct davinci_gpio_controller, chip)
 
 static void __iomem *gpio_base;
-static unsigned offset_array[5] = {0x10, 0x38, 0x60, 0x88, 0xb0};
+
+static struct davinci_gpio_regs __iomem *gpio2regs(unsigned gpio)
+{
+	void __iomem *ptr;
+
+	if (gpio < 32 * 1)
+		ptr = gpio_base + 0x10;
+	else if (gpio < 32 * 2)
+		ptr = gpio_base + 0x38;
+	else if (gpio < 32 * 3)
+		ptr = gpio_base + 0x60;
+	else if (gpio < 32 * 4)
+		ptr = gpio_base + 0x88;
+	else if (gpio < 32 * 5)
+		ptr = gpio_base + 0xb0;
+	else
+		ptr = NULL;
+	return ptr;
+}
 
 static inline struct davinci_gpio_regs __iomem *irq2regs(struct irq_data *d)
 {
@@ -179,14 +197,13 @@ static int davinci_gpio_of_xlate(struct gpio_chip *gc,
 
 static int davinci_gpio_probe(struct platform_device *pdev)
 {
-	int i, base, temp_ctrl_base;
-	unsigned ngpio, nbank;
+	int i, base;
+	unsigned ngpio;
 	struct davinci_gpio_controller *chips;
 	struct davinci_gpio_platform_data *pdata;
 	struct davinci_gpio_regs __iomem *regs;
 	struct device *dev = &pdev->dev;
 	struct resource *res;
-	static int bank_base;
 
 	pdata = davinci_gpio_get_pdata(pdev);
 	if (!pdata) {
@@ -210,9 +227,8 @@ static int davinci_gpio_probe(struct platform_device *pdev)
 	if (WARN_ON(ARCH_NR_GPIOS < ngpio))
 		ngpio = ARCH_NR_GPIOS;
 
-	nbank = DIV_ROUND_UP(ngpio, 32);
 	chips = devm_kzalloc(dev,
-			     nbank * sizeof(struct davinci_gpio_controller),
+			     ngpio * sizeof(struct davinci_gpio_controller),
 			     GFP_KERNEL);
 	if (!chips)
 		return -ENOMEM;
@@ -222,8 +238,6 @@ static int davinci_gpio_probe(struct platform_device *pdev)
 	if (IS_ERR(gpio_base))
 		return PTR_ERR(gpio_base);
 
-	temp_ctrl_base = bank_base;
-
 	for (i = 0, base = 0; base < ngpio; i++, base += 32) {
 		chips[i].chip.label = "DaVinci";
 
@@ -232,14 +246,10 @@ static int davinci_gpio_probe(struct platform_device *pdev)
 		chips[i].chip.direction_output = davinci_direction_out;
 		chips[i].chip.set = davinci_gpio_set;
 
-		chips[i].chip.base = bank_base;
-		chips[i].ctrl_base = temp_ctrl_base;
-		bank_base += 32;
+		chips[i].chip.base = base;
 		chips[i].chip.ngpio = ngpio - base;
 		if (chips[i].chip.ngpio > 32)
 			chips[i].chip.ngpio = 32;
-		else
-			bank_base = ngpio;
 
 #ifdef CONFIG_OF_GPIO
 		chips[i].chip.of_gpio_n_cells = 2;
@@ -249,7 +259,7 @@ static int davinci_gpio_probe(struct platform_device *pdev)
 #endif
 		spin_lock_init(&chips[i].lock);
 
-		regs = gpio_base + offset_array[i];
+		regs = gpio2regs(base);
 		chips[i].regs = regs;
 		chips[i].set_data = &regs->set_data;
 		chips[i].clr_data = &regs->clr_data;
@@ -327,7 +337,7 @@ static void gpio_irq_handler(struct irq_desc *desc)
 	g = (struct davinci_gpio_regs __iomem *)d->regs;
 
 	/* we only care about one bank */
-	if (irq == d->birq2)
+	if (irq & 1)
 		mask <<= 16;
 
 	/* temporarily mask (level sensitive) parent IRQ */
@@ -335,7 +345,6 @@ static void gpio_irq_handler(struct irq_desc *desc)
 	while (1) {
 		u32		status;
 		int		bit;
-		irq_hw_number_t hw_irq;
 
 		/* ack any irqs */
 		status = readl_relaxed(&g->intstat) & mask;
@@ -348,13 +357,9 @@ static void gpio_irq_handler(struct irq_desc *desc)
 		while (status) {
 			bit = __ffs(status);
 			status &= ~BIT(bit);
-			/* Max number of gpios per controller is 144 so
-			 * hw_irq will be in [0..143]
-			 */
-			hw_irq = (d->chip.base - d->ctrl_base) + bit;
-
 			generic_handle_irq(
-				irq_find_mapping(d->irq_domain, hw_irq));
+				irq_find_mapping(d->irq_domain,
+						 d->chip.base + bit));
 		}
 	}
 	chained_irq_exit(irq_desc_get_chip(desc), desc);
@@ -364,17 +369,11 @@ static void gpio_irq_handler(struct irq_desc *desc)
 static int gpio_to_irq_banked(struct gpio_chip *chip, unsigned offset)
 {
 	struct davinci_gpio_controller *d = chip2controller(chip);
-	irq_hw_number_t hw_irq;
 
-	if (d->irq_domain) {
-		/* Max number of gpios per controller is 144 so
-		 * hw_irq will be in [0..143]
-		 */
-		hw_irq = (d->chip.base - d->ctrl_base) + offset;
-		return irq_create_mapping(d->irq_domain, hw_irq);
-	} else {
+	if (d->irq_domain)
+		return irq_create_mapping(d->irq_domain, d->chip.base + offset);
+	else
 		return -ENXIO;
-	}
 }
 
 static int gpio_to_irq_unbanked(struct gpio_chip *chip, unsigned offset)
@@ -416,9 +415,7 @@ static int
 davinci_gpio_irq_map(struct irq_domain *d, unsigned int irq,
 		     irq_hw_number_t hw)
 {
-	struct davinci_gpio_controller *chips =
-				(struct davinci_gpio_controller *)d->host_data;
-	struct davinci_gpio_regs __iomem *g = chips[hw / 32].regs;
+	struct davinci_gpio_regs __iomem *g = gpio2regs(hw);
 
 	irq_set_chip_and_handler_name(irq, &gpio_irqchip, handle_simple_irq,
 				"davinci_gpio");
@@ -454,26 +451,6 @@ static struct irq_chip *keystone_gpio_get_irq_chip(unsigned int irq)
 
 static const struct of_device_id davinci_gpio_ids[];
 
-struct gpio_driver_data {
-	gpio_get_irq_chip_cb_t gpio_get_irq_chip;
-	bool clk_optional;
-};
-
-static struct gpio_driver_data davinci_data = {
-	.gpio_get_irq_chip = davinci_gpio_get_irq_chip,
-	.clk_optional = false,
-};
-
-static struct gpio_driver_data keystone_data = {
-	.gpio_get_irq_chip = keystone_gpio_get_irq_chip,
-	.clk_optional = false,
-};
-
-static struct gpio_driver_data k2g_data = {
-	.gpio_get_irq_chip = keystone_gpio_get_irq_chip,
-	.clk_optional = true,
-};
-
 /*
  * NOTE:  for suspend/resume, probably best to make a platform_device with
  * suspend_late/resume_resume calls hooking into results of the set_wake()
@@ -497,7 +474,6 @@ static int davinci_gpio_irq_setup(struct platform_device *pdev)
 	struct irq_domain	*irq_domain = NULL;
 	const struct of_device_id *match;
 	struct irq_chip *irq_chip;
-	struct gpio_driver_data *driver_data = NULL;
 	gpio_get_irq_chip_cb_t gpio_get_irq_chip;
 
 	/*
@@ -506,10 +482,8 @@ static int davinci_gpio_irq_setup(struct platform_device *pdev)
 	gpio_get_irq_chip = davinci_gpio_get_irq_chip;
 	match = of_match_device(of_match_ptr(davinci_gpio_ids),
 				dev);
-	if (match) {
-		driver_data = (struct gpio_driver_data *)match->data;
-		gpio_get_irq_chip = driver_data->gpio_get_irq_chip;
-	}
+	if (match)
+		gpio_get_irq_chip = (gpio_get_irq_chip_cb_t)match->data;
 
 	ngpio = pdata->ngpio;
 	res = platform_get_resource(pdev, IORESOURCE_IRQ, 0);
@@ -525,9 +499,6 @@ static int davinci_gpio_irq_setup(struct platform_device *pdev)
 		return -ENODEV;
 	}
 
-	if (driver_data && driver_data->clk_optional)
-		goto skip_clk_handling;
-
 	clk = devm_clk_get(dev, "gpio");
 	if (IS_ERR(clk)) {
 		printk(KERN_ERR "Error %ld getting gpio clock?\n",
@@ -536,7 +507,6 @@ static int davinci_gpio_irq_setup(struct platform_device *pdev)
 	}
 	clk_prepare_enable(clk);
 
-skip_clk_handling:
 	if (!pdata->gpio_unbanked) {
 		irq = irq_alloc_descs(-1, 0, ngpio, 0);
 		if (irq < 0) {
@@ -544,7 +514,7 @@ skip_clk_handling:
 			return irq;
 		}
 
-		irq_domain = irq_domain_add_legacy(dev->of_node, ngpio, irq, 0,
+		irq_domain = irq_domain_add_legacy(NULL, ngpio, irq, 0,
 							&davinci_gpio_irq_ops,
 							chips);
 		if (!irq_domain) {
@@ -583,7 +553,7 @@ skip_clk_handling:
 		irq_chip->irq_set_type = gpio_irq_type_unbanked;
 
 		/* default trigger: both edges */
-		g = chips[0].regs;
+		g = gpio2regs(0);
 		writel_relaxed(~0, &g->set_falling);
 		writel_relaxed(~0, &g->set_rising);
 
@@ -603,16 +573,10 @@ skip_clk_handling:
 	 */
 	for (gpio = 0, bank = 0; gpio < ngpio; bank++, bank_irq++, gpio += 16) {
 		/* disabled by default, enabled only as needed */
-		g = chips[bank / 2].regs;
+		g = gpio2regs(gpio);
 		writel_relaxed(~0, &g->clr_falling);
 		writel_relaxed(~0, &g->clr_rising);
 
-		bank_irq = platform_get_irq(pdev, bank);
-		if (bank % 2)
-			chips[bank / 2].birq2 = bank_irq;
-		else
-			chips[bank / 2].birq1 = bank_irq;
-
 		/*
 		 * Each chip handles 32 gpios, and each irq bank consists of 16
 		 * gpio irqs. Pass the irq bank's corresponding controller to
@@ -636,18 +600,8 @@ done:
 
 #if IS_ENABLED(CONFIG_OF)
 static const struct of_device_id davinci_gpio_ids[] = {
-	{
-		.compatible = "ti,keystone-gpio",
-		.data = &keystone_data,
-	},
-	{
-		.compatible = "ti,dm6441-gpio",
-		.data = &davinci_data,
-	},
-	{
-		.compatible = "ti,k2g-gpio",
-		.data = &k2g_data,
-	},
+	{ .compatible = "ti,keystone-gpio", keystone_gpio_get_irq_chip},
+	{ .compatible = "ti,dm6441-gpio", davinci_gpio_get_irq_chip},
 	{ /* sentinel */ },
 };
 MODULE_DEVICE_TABLE(of, davinci_gpio_ids);
diff --git a/drivers/memory/omap-gpmc.c b/drivers/memory/omap-gpmc.c
index 46476c6ad37a..55cba89dbdb8 100644
--- a/drivers/memory/omap-gpmc.c
+++ b/drivers/memory/omap-gpmc.c
@@ -21,9 +21,7 @@
 #include <linux/spinlock.h>
 #include <linux/io.h>
 #include <linux/module.h>
-#include <linux/gpio/driver.h>
 #include <linux/interrupt.h>
-#include <linux/irqdomain.h>
 #include <linux/platform_device.h>
 #include <linux/of.h>
 #include <linux/of_address.h>
@@ -31,6 +29,7 @@
 #include <linux/of_device.h>
 #include <linux/of_platform.h>
 #include <linux/omap-gpmc.h>
+#include <linux/mtd/nand.h>
 #include <linux/pm_runtime.h>
 
 #include <linux/platform_data/mtd-nand-omap2.h>
@@ -82,8 +81,6 @@
 
 #define GPMC_CONFIG_LIMITEDADDRESS		BIT(1)
 
-#define GPMC_STATUS_EMPTYWRITEBUFFERSTATUS	BIT(0)
-
 #define	GPMC_CONFIG2_CSEXTRADELAY		BIT(7)
 #define	GPMC_CONFIG3_ADVEXTRADELAY		BIT(7)
 #define	GPMC_CONFIG4_OEEXTRADELAY		BIT(7)
@@ -95,14 +92,6 @@
 #define GPMC_CS_SIZE		0x30
 #define	GPMC_BCH_SIZE		0x10
 
-/*
- * The first 1MB of GPMC address space is typically mapped to
- * the internal ROM. Never allocate the first page, to
- * facilitate bug detection; even if we didn't boot from ROM.
- * As GPMC minimum partition size is 16MB we can only start from
- * there.
- */
-#define GPMC_MEM_START		0x1000000
 #define GPMC_MEM_END		0x3FFFFFFF
 
 #define GPMC_CHUNK_SHIFT	24		/* 16 MB */
@@ -136,6 +125,7 @@
 #define GPMC_CONFIG_RDY_BSY	0x00000001
 #define GPMC_CONFIG_DEV_SIZE	0x00000002
 #define GPMC_CONFIG_DEV_TYPE	0x00000003
+#define GPMC_SET_IRQ_STATUS	0x00000004
 
 #define GPMC_CONFIG1_WRAPBURST_SUPP     (1 << 31)
 #define GPMC_CONFIG1_READMULTIPLE_SUPP  (1 << 30)
@@ -184,12 +174,16 @@
 #define GPMC_CONFIG_WRITEPROTECT	0x00000010
 #define WR_RD_PIN_MONITORING		0x00600000
 
+#define GPMC_ENABLE_IRQ		0x0000000d
+
 /* ECC commands */
 #define GPMC_ECC_READ		0 /* Reset Hardware ECC for read */
 #define GPMC_ECC_WRITE		1 /* Reset Hardware ECC for write */
 #define GPMC_ECC_READSYN	2 /* Reset before syndrom is read back */
 
-#define	GPMC_NR_NAND_IRQS	2 /* number of NAND specific IRQs */
+/* XXX: Only NAND irq has been considered,currently these are the only ones used
+ */
+#define	GPMC_NR_IRQ		2
 
 enum gpmc_clk_domain {
 	GPMC_CD_FCLK,
@@ -205,6 +199,11 @@ struct gpmc_cs_data {
 	struct resource mem;
 };
 
+struct gpmc_client_irq	{
+	unsigned		irq;
+	u32			bitmask;
+};
+
 /* Structure to save gpmc cs context */
 struct gpmc_cs_config {
 	u32 config1;
@@ -232,15 +231,9 @@ struct omap3_gpmc_regs {
 	struct gpmc_cs_config cs_context[GPMC_CS_NUM];
 };
 
-struct gpmc_device {
-	struct device *dev;
-	int irq;
-	struct irq_chip irq_chip;
-	struct gpio_chip gpio_chip;
-	int nirqs;
-};
-
-static struct irq_domain *gpmc_irq_domain;
+static struct gpmc_client_irq gpmc_client_irq[GPMC_NR_IRQ];
+static struct irq_chip gpmc_irq_chip;
+static int gpmc_irq_start;
 
 static struct resource	gpmc_mem_root;
 static struct gpmc_cs_data gpmc_cs[GPMC_CS_NUM];
@@ -248,6 +241,8 @@ static DEFINE_SPINLOCK(gpmc_mem_lock);
 /* Define chip-selects as reserved by default until probe completes */
 static unsigned int gpmc_cs_num = GPMC_CS_NUM;
 static unsigned int gpmc_nr_waitpins;
+static struct device *gpmc_dev;
+static int gpmc_irq;
 static resource_size_t phys_base, mem_size;
 static unsigned gpmc_capability;
 static void __iomem *gpmc_base;
@@ -1039,6 +1034,14 @@ int gpmc_configure(int cmd, int wval)
 	u32 regval;
 
 	switch (cmd) {
+	case GPMC_ENABLE_IRQ:
+		gpmc_write_reg(GPMC_IRQENABLE, wval);
+		break;
+
+	case GPMC_SET_IRQ_STATUS:
+		gpmc_write_reg(GPMC_IRQSTATUS, wval);
+		break;
+
 	case GPMC_CONFIG_WP:
 		regval = gpmc_read_reg(GPMC_CONFIG);
 		if (wval)
@@ -1061,7 +1064,7 @@ void gpmc_update_nand_reg(struct gpmc_nand_regs *reg, int cs)
 {
 	int i;
 
-	reg->gpmc_status = NULL;	/* deprecated */
+	reg->gpmc_status = gpmc_base + GPMC_STATUS;
 	reg->gpmc_nand_command = gpmc_base + GPMC_CS0_OFFSET +
 				GPMC_CS_NAND_COMMAND + GPMC_CS_SIZE * cs;
 	reg->gpmc_nand_address = gpmc_base + GPMC_CS0_OFFSET +
@@ -1095,201 +1098,87 @@ void gpmc_update_nand_reg(struct gpmc_nand_regs *reg, int cs)
 	}
 }
 
-static bool gpmc_nand_writebuffer_empty(void)
-{
-	if (gpmc_read_reg(GPMC_STATUS) & GPMC_STATUS_EMPTYWRITEBUFFERSTATUS)
-		return true;
-
-	return false;
-}
-
-static struct gpmc_nand_ops nand_ops = {
-	.nand_writebuffer_empty = gpmc_nand_writebuffer_empty,
-};
-
-/**
- * gpmc_omap_get_nand_ops - Get the GPMC NAND interface
- * @regs: the GPMC NAND register map exclusive for NAND use.
- * @cs: GPMC chip select number on which the NAND sits. The
- *      register map returned will be specific to this chip select.
- *
- * Returns NULL on error e.g. invalid cs.
- */
-struct gpmc_nand_ops *gpmc_omap_get_nand_ops(struct gpmc_nand_regs *reg, int cs)
-{
-	if (cs >= gpmc_cs_num)
-		return NULL;
-
-	gpmc_update_nand_reg(reg, cs);
-
-	return &nand_ops;
-}
-EXPORT_SYMBOL_GPL(gpmc_omap_get_nand_ops);
-
 int gpmc_get_client_irq(unsigned irq_config)
 {
-	if (!gpmc_irq_domain) {
-		pr_warn("%s called before GPMC IRQ domain available\n",
-		__func__);
-		return 0;
-	}
+	int i;
 
-	/* we restrict this to NAND IRQs only */
-	if (irq_config >= GPMC_NR_NAND_IRQS)
+	if (hweight32(irq_config) > 1)
 		return 0;
 
-	return irq_create_mapping(gpmc_irq_domain, irq_config);
+	for (i = 0; i < GPMC_NR_IRQ; i++)
+		if (gpmc_client_irq[i].bitmask & irq_config)
+			return gpmc_client_irq[i].irq;
+
+	return 0;
 }
 
-static int gpmc_irq_endis(unsigned long hwirq, bool endis)
+static int gpmc_irq_endis(unsigned irq, bool endis)
 {
+	int i;
 	u32 regval;
 
-	/* bits GPMC_NR_NAND_IRQS to 8 are reserved */
-	if (hwirq >= GPMC_NR_NAND_IRQS)
-		hwirq += 8 - GPMC_NR_NAND_IRQS;
-
-	regval = gpmc_read_reg(GPMC_IRQENABLE);
-	if (endis)
-		regval |= BIT(hwirq);
-	else
-		regval &= ~BIT(hwirq);
-	gpmc_write_reg(GPMC_IRQENABLE, regval);
+	for (i = 0; i < GPMC_NR_IRQ; i++)
+		if (irq == gpmc_client_irq[i].irq) {
+			regval = gpmc_read_reg(GPMC_IRQENABLE);
+			if (endis)
+				regval |= gpmc_client_irq[i].bitmask;
+			else
+				regval &= ~gpmc_client_irq[i].bitmask;
+			gpmc_write_reg(GPMC_IRQENABLE, regval);
+			break;
+		}
 
 	return 0;
 }
 
 static void gpmc_irq_disable(struct irq_data *p)
 {
-	gpmc_irq_endis(p->hwirq, false);
+	gpmc_irq_endis(p->irq, false);
 }
 
 static void gpmc_irq_enable(struct irq_data *p)
 {
-	gpmc_irq_endis(p->hwirq, true);
+	gpmc_irq_endis(p->irq, true);
 }
 
-static void gpmc_irq_mask(struct irq_data *d)
-{
-	gpmc_irq_endis(d->hwirq, false);
-}
+static void gpmc_irq_noop(struct irq_data *data) { }
 
-static void gpmc_irq_unmask(struct irq_data *d)
-{
-	gpmc_irq_endis(d->hwirq, true);
-}
+static unsigned int gpmc_irq_noop_ret(struct irq_data *data) { return 0; }
 
-static void gpmc_irq_edge_config(unsigned long hwirq, bool rising_edge)
+static int gpmc_setup_irq(void)
 {
+	int i;
 	u32 regval;
 
-	/* NAND IRQs polarity is not configurable */
-	if (hwirq < GPMC_NR_NAND_IRQS)
-		return;
-
-	/* WAITPIN starts at BIT 8 */
-	hwirq += 8 - GPMC_NR_NAND_IRQS;
-
-	regval = gpmc_read_reg(GPMC_CONFIG);
-	if (rising_edge)
-		regval &= ~BIT(hwirq);
-	else
-		regval |= BIT(hwirq);
-
-	gpmc_write_reg(GPMC_CONFIG, regval);
-}
-
-static void gpmc_irq_ack(struct irq_data *d)
-{
-	unsigned hwirq = d->hwirq;
-
-	/* skip reserved bits */
-	if (hwirq >= GPMC_NR_NAND_IRQS)
-		hwirq += 8 - GPMC_NR_NAND_IRQS;
-
-	/* Setting bit to 1 clears (or Acks) the interrupt */
-	gpmc_write_reg(GPMC_IRQSTATUS, BIT(hwirq));
-}
-
-static int gpmc_irq_set_type(struct irq_data *d, unsigned trigger)
-{
-	/* can't set type for NAND IRQs */
-	if (d->hwirq < GPMC_NR_NAND_IRQS)
-		return -EINVAL;
-
-	/* We can support either rising or falling edge at a time */
-	if (trigger == IRQ_TYPE_EDGE_FALLING)
-		gpmc_irq_edge_config(d->hwirq, false);
-	else if (trigger == IRQ_TYPE_EDGE_RISING)
-		gpmc_irq_edge_config(d->hwirq, true);
-	else
+	if (!gpmc_irq)
 		return -EINVAL;
 
-	return 0;
-}
-
-static int gpmc_irq_map(struct irq_domain *d, unsigned int virq,
-			irq_hw_number_t hw)
-{
-	struct gpmc_device *gpmc = d->host_data;
-
-	irq_set_chip_data(virq, gpmc);
-	if (hw < GPMC_NR_NAND_IRQS) {
-		irq_modify_status(virq, IRQ_NOREQUEST, IRQ_NOAUTOEN);
-		irq_set_chip_and_handler(virq, &gpmc->irq_chip,
-					 handle_simple_irq);
-	} else {
-		irq_set_chip_and_handler(virq, &gpmc->irq_chip,
-					 handle_edge_irq);
+	gpmc_irq_start = irq_alloc_descs(-1, 0, GPMC_NR_IRQ, 0);
+	if (gpmc_irq_start < 0) {
+		pr_err("irq_alloc_descs failed\n");
+		return gpmc_irq_start;
 	}
 
-	return 0;
-}
-
-static const struct irq_domain_ops gpmc_irq_domain_ops = {
-	.map    = gpmc_irq_map,
-	.xlate  = irq_domain_xlate_twocell,
-};
-
-static irqreturn_t gpmc_handle_irq(int irq, void *data)
-{
-	int hwirq, virq;
-	u32 regval, regvalx;
-	struct gpmc_device *gpmc = data;
-
-	regval = gpmc_read_reg(GPMC_IRQSTATUS);
-	regvalx = regval;
-
-	if (!regval)
-		return IRQ_NONE;
-
-	for (hwirq = 0; hwirq < gpmc->nirqs; hwirq++) {
-		/* skip reserved status bits */
-		if (hwirq == GPMC_NR_NAND_IRQS)
-			regvalx >>= 8 - GPMC_NR_NAND_IRQS;
-
-		if (regvalx & BIT(hwirq)) {
-			virq = irq_find_mapping(gpmc_irq_domain, hwirq);
-			if (!virq) {
-				dev_warn(gpmc->dev,
-					 "spurious irq detected hwirq %d, virq %d\n",
-					 hwirq, virq);
-			}
-
-			generic_handle_irq(virq);
-		}
+	gpmc_irq_chip.name = "gpmc";
+	gpmc_irq_chip.irq_startup = gpmc_irq_noop_ret;
+	gpmc_irq_chip.irq_enable = gpmc_irq_enable;
+	gpmc_irq_chip.irq_disable = gpmc_irq_disable;
+	gpmc_irq_chip.irq_shutdown = gpmc_irq_noop;
+	gpmc_irq_chip.irq_ack = gpmc_irq_noop;
+	gpmc_irq_chip.irq_mask = gpmc_irq_noop;
+	gpmc_irq_chip.irq_unmask = gpmc_irq_noop;
+
+	gpmc_client_irq[0].bitmask = GPMC_IRQ_FIFOEVENTENABLE;
+	gpmc_client_irq[1].bitmask = GPMC_IRQ_COUNT_EVENT;
+
+	for (i = 0; i < GPMC_NR_IRQ; i++) {
+		gpmc_client_irq[i].irq = gpmc_irq_start + i;
+		irq_set_chip_and_handler(gpmc_client_irq[i].irq,
+					&gpmc_irq_chip, handle_simple_irq);
+		irq_modify_status(gpmc_client_irq[i].irq, IRQ_NOREQUEST,
+				  IRQ_NOAUTOEN);
 	}
 
-	gpmc_write_reg(GPMC_IRQSTATUS, regval);
-
-	return IRQ_HANDLED;
-}
-
-static int gpmc_setup_irq(struct gpmc_device *gpmc)
-{
-	u32 regval;
-	int rc;
-
 	/* Disable interrupts */
 	gpmc_write_reg(GPMC_IRQENABLE, 0);
 
@@ -1297,45 +1186,22 @@ static int gpmc_setup_irq(struct gpmc_device *gpmc)
 	regval = gpmc_read_reg(GPMC_IRQSTATUS);
 	gpmc_write_reg(GPMC_IRQSTATUS, regval);
 
-	gpmc->irq_chip.name = "gpmc";
-	gpmc->irq_chip.irq_enable = gpmc_irq_enable;
-	gpmc->irq_chip.irq_disable = gpmc_irq_disable;
-	gpmc->irq_chip.irq_ack = gpmc_irq_ack;
-	gpmc->irq_chip.irq_mask = gpmc_irq_mask;
-	gpmc->irq_chip.irq_unmask = gpmc_irq_unmask;
-	gpmc->irq_chip.irq_set_type = gpmc_irq_set_type;
-
-	gpmc_irq_domain = irq_domain_add_linear(gpmc->dev->of_node,
-						gpmc->nirqs,
-						&gpmc_irq_domain_ops,
-						gpmc);
-	if (!gpmc_irq_domain) {
-		dev_err(gpmc->dev, "IRQ domain add failed\n");
-		return -ENODEV;
-	}
-
-	rc = request_irq(gpmc->irq, gpmc_handle_irq, 0, "gpmc", gpmc);
-	if (rc) {
-		dev_err(gpmc->dev, "failed to request irq %d: %d\n",
-			gpmc->irq, rc);
-		irq_domain_remove(gpmc_irq_domain);
-		gpmc_irq_domain = NULL;
-	}
-
-	return rc;
+	return request_irq(gpmc_irq, gpmc_handle_irq, 0, "gpmc", NULL);
 }
 
-static int gpmc_free_irq(struct gpmc_device *gpmc)
+static int gpmc_free_irq(void)
 {
-	int hwirq;
+	int i;
 
-	free_irq(gpmc->irq, gpmc);
+	if (gpmc_irq)
+		free_irq(gpmc_irq, NULL);
 
-	for (hwirq = 0; hwirq < gpmc->nirqs; hwirq++)
-		irq_dispose_mapping(irq_find_mapping(gpmc_irq_domain, hwirq));
+	for (i = 0; i < GPMC_NR_IRQ; i++) {
+		irq_set_handler(gpmc_client_irq[i].irq, NULL);
+		irq_set_chip(gpmc_client_irq[i].irq, &no_irq_chip);
+	}
 
-	irq_domain_remove(gpmc_irq_domain);
-	gpmc_irq_domain = NULL;
+	irq_free_descs(gpmc_irq_start, GPMC_NR_IRQ);
 
 	return 0;
 }
@@ -1356,7 +1222,12 @@ static void gpmc_mem_init(void)
 {
 	int cs;
 
-	gpmc_mem_root.start = GPMC_MEM_START;
+	/*
+	 * The first 1MB of GPMC address space is typically mapped to
+	 * the internal ROM. Never allocate the first page, to
+	 * facilitate bug detection; even if we didn't boot from ROM.
+	 */
+	gpmc_mem_root.start = SZ_1M;
 	gpmc_mem_root.end = GPMC_MEM_END;
 
 	/* Reserve all regions that has been set up by bootloader */
@@ -1895,6 +1766,105 @@ static void __maybe_unused gpmc_read_timings_dt(struct device_node *np,
 		of_property_read_bool(np, "gpmc,time-para-granularity");
 }
 
+#if IS_ENABLED(CONFIG_MTD_NAND)
+
+static const char * const nand_xfer_types[] = {
+	[NAND_OMAP_PREFETCH_POLLED]		= "prefetch-polled",
+	[NAND_OMAP_POLLED]			= "polled",
+	[NAND_OMAP_PREFETCH_DMA]		= "prefetch-dma",
+	[NAND_OMAP_PREFETCH_IRQ]		= "prefetch-irq",
+};
+
+static int gpmc_probe_nand_child(struct platform_device *pdev,
+				 struct device_node *child)
+{
+	u32 val;
+	const char *s;
+	struct gpmc_timings gpmc_t;
+	struct omap_nand_platform_data *gpmc_nand_data;
+
+	if (of_property_read_u32(child, "reg", &val) < 0) {
+		dev_err(&pdev->dev, "%s has no 'reg' property\n",
+			child->full_name);
+		return -ENODEV;
+	}
+
+	gpmc_nand_data = devm_kzalloc(&pdev->dev, sizeof(*gpmc_nand_data),
+				      GFP_KERNEL);
+	if (!gpmc_nand_data)
+		return -ENOMEM;
+
+	gpmc_nand_data->cs = val;
+	gpmc_nand_data->of_node = child;
+
+	/* Detect availability of ELM module */
+	gpmc_nand_data->elm_of_node = of_parse_phandle(child, "ti,elm-id", 0);
+	if (gpmc_nand_data->elm_of_node == NULL)
+		gpmc_nand_data->elm_of_node =
+					of_parse_phandle(child, "elm_id", 0);
+
+	/* select ecc-scheme for NAND */
+	if (of_property_read_string(child, "ti,nand-ecc-opt", &s)) {
+		pr_err("%s: ti,nand-ecc-opt not found\n", __func__);
+		return -ENODEV;
+	}
+
+	if (!strcmp(s, "sw"))
+		gpmc_nand_data->ecc_opt = OMAP_ECC_HAM1_CODE_SW;
+	else if (!strcmp(s, "ham1") ||
+		 !strcmp(s, "hw") || !strcmp(s, "hw-romcode"))
+		gpmc_nand_data->ecc_opt =
+				OMAP_ECC_HAM1_CODE_HW;
+	else if (!strcmp(s, "bch4"))
+		if (gpmc_nand_data->elm_of_node)
+			gpmc_nand_data->ecc_opt =
+				OMAP_ECC_BCH4_CODE_HW;
+		else
+			gpmc_nand_data->ecc_opt =
+				OMAP_ECC_BCH4_CODE_HW_DETECTION_SW;
+	else if (!strcmp(s, "bch8"))
+		if (gpmc_nand_data->elm_of_node)
+			gpmc_nand_data->ecc_opt =
+				OMAP_ECC_BCH8_CODE_HW;
+		else
+			gpmc_nand_data->ecc_opt =
+				OMAP_ECC_BCH8_CODE_HW_DETECTION_SW;
+	else if (!strcmp(s, "bch16"))
+		if (gpmc_nand_data->elm_of_node)
+			gpmc_nand_data->ecc_opt =
+				OMAP_ECC_BCH16_CODE_HW;
+		else
+			pr_err("%s: BCH16 requires ELM support\n", __func__);
+	else
+		pr_err("%s: ti,nand-ecc-opt invalid value\n", __func__);
+
+	/* select data transfer mode for NAND controller */
+	if (!of_property_read_string(child, "ti,nand-xfer-type", &s))
+		for (val = 0; val < ARRAY_SIZE(nand_xfer_types); val++)
+			if (!strcasecmp(s, nand_xfer_types[val])) {
+				gpmc_nand_data->xfer_type = val;
+				break;
+			}
+
+	gpmc_nand_data->flash_bbt = of_get_nand_on_flash_bbt(child);
+
+	val = of_get_nand_bus_width(child);
+	if (val == 16)
+		gpmc_nand_data->devsize = NAND_BUSWIDTH_16;
+
+	gpmc_read_timings_dt(child, &gpmc_t);
+	gpmc_nand_init(gpmc_nand_data, &gpmc_t);
+
+	return 0;
+}
+#else
+static int gpmc_probe_nand_child(struct platform_device *pdev,
+				 struct device_node *child)
+{
+	return 0;
+}
+#endif
+
 #if IS_ENABLED(CONFIG_MTD_ONENAND)
 static int gpmc_probe_onenand_child(struct platform_device *pdev,
 				 struct device_node *child)
@@ -1950,8 +1920,6 @@ static int gpmc_probe_generic_child(struct platform_device *pdev,
 	const char *name;
 	int ret, cs;
 	u32 val;
-	struct gpio_desc *waitpin_desc = NULL;
-	struct gpmc_device *gpmc = platform_get_drvdata(pdev);
 
 	if (of_property_read_u32(child, "reg", &cs) < 0) {
 		dev_err(&pdev->dev, "%s has no 'reg' property\n",
@@ -2012,81 +1980,23 @@ static int gpmc_probe_generic_child(struct platform_device *pdev,
 	if (ret < 0) {
 		dev_err(&pdev->dev, "cannot remap GPMC CS %d to %pa\n",
 			cs, &res.start);
-		if (res.start < GPMC_MEM_START) {
-			dev_info(&pdev->dev,
-				 "GPMC CS %d start cannot be lesser than 0x%x\n",
-				 cs, GPMC_MEM_START);
-		} else if (res.end > GPMC_MEM_END) {
-			dev_info(&pdev->dev,
-				 "GPMC CS %d end cannot be greater than 0x%x\n",
-				 cs, GPMC_MEM_END);
-		}
 		goto err;
 	}
 
-	if (of_node_cmp(child->name, "nand") == 0) {
-		/* Warn about older DT blobs with no compatible property */
-		if (!of_property_read_bool(child, "compatible")) {
-			dev_warn(&pdev->dev,
-				 "Incompatible NAND node: missing compatible");
-			ret = -EINVAL;
-			goto err;
-		}
-	}
-
-	if (of_device_is_compatible(child, "ti,omap2-nand")) {
-		/* NAND specific setup */
-		u32 val;
-
-		val = of_get_nand_bus_width(child);
-		switch (val) {
-		case 8:
-			gpmc_s.device_width = GPMC_DEVWIDTH_8BIT;
-			break;
-		case 16:
-			gpmc_s.device_width = GPMC_DEVWIDTH_16BIT;
-			break;
-		default:
-			dev_err(&pdev->dev, "%s: invalid 'nand-bus-width'\n",
-				child->name);
-			ret = -EINVAL;
-			goto err;
-		}
-
-		/* disable write protect */
-		gpmc_configure(GPMC_CONFIG_WP, 0);
-		gpmc_s.device_nand = true;
-	} else {
-		ret = of_property_read_u32(child, "bank-width",
-					   &gpmc_s.device_width);
-		if (ret < 0)
-			goto err;
-	}
-
-	/* Reserve wait pin if it is required and valid */
-	if (gpmc_s.wait_on_read || gpmc_s.wait_on_write) {
-		unsigned wait_pin = gpmc_s.wait_pin;
-
-		waitpin_desc = gpiochip_request_own_desc(&gpmc->gpio_chip,
-							 wait_pin, "WAITPIN");
-		if (IS_ERR(waitpin_desc)) {
-			dev_err(&pdev->dev, "invalid wait-pin: %d\n", wait_pin);
-			ret = PTR_ERR(waitpin_desc);
-			goto err;
-		}
-	}
+	ret = of_property_read_u32(child, "bank-width", &gpmc_s.device_width);
+	if (ret < 0)
+		goto err;
 
 	gpmc_cs_show_timings(cs, "before gpmc_cs_program_settings");
-
 	ret = gpmc_cs_program_settings(cs, &gpmc_s);
 	if (ret < 0)
-		goto err_cs;
+		goto err;
 
 	ret = gpmc_cs_set_timings(cs, &gpmc_t, &gpmc_s);
 	if (ret) {
 		dev_err(&pdev->dev, "failed to set gpmc timings for: %s\n",
 			child->name);
-		goto err_cs;
+		goto err;
 	}
 
 	/* Clear limited address i.e. enable A26-A11 */
@@ -2117,79 +2027,16 @@ err_child_fail:
 	dev_err(&pdev->dev, "failed to create gpmc child %s\n", child->name);
 	ret = -ENODEV;
 
-err_cs:
-	if (waitpin_desc)
-		gpiochip_free_own_desc(waitpin_desc);
-
 err:
 	gpmc_cs_free(cs);
 
 	return ret;
 }
 
-static int gpmc_gpio_get_direction(struct gpio_chip *chip, unsigned offset)
-{
-	return 1;	/* we're input only */
-}
-
-static int gpmc_gpio_direction_input(struct gpio_chip *chip, unsigned offset)
-{
-	return 0;	/* we're input only */
-}
-
-static int gpmc_gpio_direction_output(struct gpio_chip *chip, unsigned offset,
-				      int value)
-{
-	return -EINVAL;	/* we're input only */
-}
-
-static void gpmc_gpio_set(struct gpio_chip *chip, unsigned offset, int value)
-{
-}
-
-static int gpmc_gpio_get(struct gpio_chip *chip, unsigned offset)
-{
-	u32 reg;
-
-	offset += 8;
-
-	reg = gpmc_read_reg(GPMC_STATUS) & BIT(offset);
-
-	return !!reg;
-}
-
-static int gpmc_gpio_init(struct gpmc_device *gpmc)
-{
-	int ret;
-
-	gpmc->gpio_chip.dev = gpmc->dev;
-	gpmc->gpio_chip.owner = THIS_MODULE;
-	gpmc->gpio_chip.label = DEVICE_NAME;
-	gpmc->gpio_chip.ngpio = gpmc_nr_waitpins;
-	gpmc->gpio_chip.get_direction = gpmc_gpio_get_direction;
-	gpmc->gpio_chip.direction_input = gpmc_gpio_direction_input;
-	gpmc->gpio_chip.direction_output = gpmc_gpio_direction_output;
-	gpmc->gpio_chip.set = gpmc_gpio_set;
-	gpmc->gpio_chip.get = gpmc_gpio_get;
-	gpmc->gpio_chip.base = -1;
-
-	ret = gpiochip_add(&gpmc->gpio_chip);
-	if (ret < 0) {
-		dev_err(gpmc->dev, "could not register gpio chip: %d\n", ret);
-		return ret;
-	}
-
-	return 0;
-}
-
-static void gpmc_gpio_exit(struct gpmc_device *gpmc)
-{
-	gpiochip_remove(&gpmc->gpio_chip);
-}
-
 static int gpmc_probe_dt(struct platform_device *pdev)
 {
 	int ret;
+	struct device_node *child;
 	const struct of_device_id *of_id =
 		of_match_device(gpmc_dt_ids, &pdev->dev);
 
@@ -2217,26 +2064,17 @@ static int gpmc_probe_dt(struct platform_device *pdev)
 		return ret;
 	}
 
-	return 0;
-}
-
-static int gpmc_probe_dt_children(struct platform_device *pdev)
-{
-	int ret;
-	struct device_node *child;
-
 	for_each_available_child_of_node(pdev->dev.of_node, child) {
 
 		if (!child->name)
 			continue;
 
-		if (of_node_cmp(child->name, "onenand") == 0)
+		if (of_node_cmp(child->name, "nand") == 0)
+			ret = gpmc_probe_nand_child(pdev, child);
+		else if (of_node_cmp(child->name, "onenand") == 0)
 			ret = gpmc_probe_onenand_child(pdev, child);
 		else
 			ret = gpmc_probe_generic_child(pdev, child);
-
-		if (ret)
-			return ret;
 	}
 
 	return 0;
@@ -2246,11 +2084,6 @@ static int gpmc_probe_dt(struct platform_device *pdev)
 {
 	return 0;
 }
-
-static int gpmc_probe_dt_children(struct platform_device *pdev)
-{
-	return 0;
-}
 #endif
 
 static int gpmc_probe(struct platform_device *pdev)
@@ -2258,14 +2091,6 @@ static int gpmc_probe(struct platform_device *pdev)
 	int rc;
 	u32 l;
 	struct resource *res;
-	struct gpmc_device *gpmc;
-
-	gpmc = devm_kzalloc(&pdev->dev, sizeof(*gpmc), GFP_KERNEL);
-	if (!gpmc)
-		return -ENOMEM;
-
-	gpmc->dev = &pdev->dev;
-	platform_set_drvdata(pdev, gpmc);
 
 	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
 	if (res == NULL)
@@ -2279,16 +2104,15 @@ static int gpmc_probe(struct platform_device *pdev)
 		return PTR_ERR(gpmc_base);
 
 	res = platform_get_resource(pdev, IORESOURCE_IRQ, 0);
-	if (!res) {
-		dev_err(&pdev->dev, "Failed to get resource: irq\n");
-		return -ENOENT;
-	}
-
-	gpmc->irq = res->start;
+	if (res == NULL)
+		dev_warn(&pdev->dev, "Failed to get resource: irq\n");
+	else
+		gpmc_irq = res->start;
 
 	gpmc_l3_clk = devm_clk_get(&pdev->dev, "fck");
 	if (IS_ERR(gpmc_l3_clk)) {
 		dev_err(&pdev->dev, "Failed to get GPMC fck\n");
+		gpmc_irq = 0;
 		return PTR_ERR(gpmc_l3_clk);
 	}
 
@@ -2297,18 +2121,11 @@ static int gpmc_probe(struct platform_device *pdev)
 		return -EINVAL;
 	}
 
-	if (pdev->dev.of_node) {
-		rc = gpmc_probe_dt(pdev);
-		if (rc)
-			return rc;
-	} else {
-		gpmc_cs_num = GPMC_CS_NUM;
-		gpmc_nr_waitpins = GPMC_NR_WAITPINS;
-	}
-
 	pm_runtime_enable(&pdev->dev);
 	pm_runtime_get_sync(&pdev->dev);
 
+	gpmc_dev = &pdev->dev;
+
 	l = gpmc_read_reg(GPMC_REVISION);
 
 	/*
@@ -2327,51 +2144,36 @@ static int gpmc_probe(struct platform_device *pdev)
 		gpmc_capability = GPMC_HAS_WR_ACCESS | GPMC_HAS_WR_DATA_MUX_BUS;
 	if (GPMC_REVISION_MAJOR(l) > 0x5)
 		gpmc_capability |= GPMC_HAS_MUX_AAD;
-	dev_info(gpmc->dev, "GPMC revision %d.%d\n", GPMC_REVISION_MAJOR(l),
+	dev_info(gpmc_dev, "GPMC revision %d.%d\n", GPMC_REVISION_MAJOR(l),
 		 GPMC_REVISION_MINOR(l));
 
 	gpmc_mem_init();
-	rc = gpmc_gpio_init(gpmc);
-	if (rc)
-		goto gpio_init_failed;
-
-	gpmc->nirqs = GPMC_NR_NAND_IRQS + gpmc_nr_waitpins;
-	rc = gpmc_setup_irq(gpmc);
-	if (rc) {
-		dev_err(gpmc->dev, "gpmc_setup_irq failed\n");
-		goto setup_irq_failed;
+
+	if (gpmc_setup_irq() < 0)
+		dev_warn(gpmc_dev, "gpmc_setup_irq failed\n");
+
+	if (!pdev->dev.of_node) {
+		gpmc_cs_num	 = GPMC_CS_NUM;
+		gpmc_nr_waitpins = GPMC_NR_WAITPINS;
 	}
 
-	rc = gpmc_probe_dt_children(pdev);
+	rc = gpmc_probe_dt(pdev);
 	if (rc < 0) {
-		dev_err(gpmc->dev, "failed to probe DT children\n");
-		goto dt_children_failed;
+		pm_runtime_put_sync(&pdev->dev);
+		dev_err(gpmc_dev, "failed to probe DT parameters\n");
+		return rc;
 	}
 
 	return 0;
-
-dt_children_failed:
-	gpmc_free_irq(gpmc);
-setup_irq_failed:
-	gpmc_gpio_exit(gpmc);
-gpio_init_failed:
-	gpmc_mem_exit();
-	pm_runtime_put_sync(&pdev->dev);
-	pm_runtime_disable(&pdev->dev);
-
-	return rc;
 }
 
 static int gpmc_remove(struct platform_device *pdev)
 {
-	struct gpmc_device *gpmc = platform_get_drvdata(pdev);
-
-	gpmc_free_irq(gpmc);
-	gpmc_gpio_exit(gpmc);
+	gpmc_free_irq();
 	gpmc_mem_exit();
 	pm_runtime_put_sync(&pdev->dev);
 	pm_runtime_disable(&pdev->dev);
-
+	gpmc_dev = NULL;
 	return 0;
 }
 
@@ -2380,18 +2182,11 @@ static int gpmc_suspend(struct device *dev)
 {
 	omap3_gpmc_save_context();
 	pm_runtime_put_sync(dev);
-
-	/* Select sleep pin state */
-	pinctrl_pm_select_sleep_state(dev);
-
 	return 0;
 }
 
 static int gpmc_resume(struct device *dev)
 {
-	/* Select default pin state */
-	pinctrl_pm_select_default_state(dev);
-
 	pm_runtime_get_sync(dev);
 	omap3_gpmc_restore_context();
 	return 0;
@@ -2424,6 +2219,25 @@ static __exit void gpmc_exit(void)
 postcore_initcall(gpmc_init);
 module_exit(gpmc_exit);
 
+static irqreturn_t gpmc_handle_irq(int irq, void *dev)
+{
+	int i;
+	u32 regval;
+
+	regval = gpmc_read_reg(GPMC_IRQSTATUS);
+
+	if (!regval)
+		return IRQ_NONE;
+
+	for (i = 0; i < GPMC_NR_IRQ; i++)
+		if (regval & gpmc_client_irq[i].bitmask)
+			generic_handle_irq(gpmc_client_irq[i].irq);
+
+	gpmc_write_reg(GPMC_IRQSTATUS, regval);
+
+	return IRQ_HANDLED;
+}
+
 static struct omap3_gpmc_regs gpmc_context;
 
 void omap3_gpmc_save_context(void)
-- 
2.11.0

